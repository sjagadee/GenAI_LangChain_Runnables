{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d977043",
   "metadata": {},
   "source": [
    "#### Now let us standardized methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be181512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a770d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def invoke(input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8380a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class DummyLLM(Runnable):\n",
    "    def __init__(self):\n",
    "        print(\"LLM initialized\")\n",
    "\n",
    "    def invoke(self, prompt):\n",
    "        response_list = [\n",
    "            \"Delhi is the capital of India\",\n",
    "            \"IPL is a poppular league in India\",\n",
    "            \"AI stands for Artificial Intelligence\"\n",
    "        ]\n",
    "        return {'response': random.choice(response_list)}\n",
    "    \n",
    "    def predict(self, prompt):\n",
    "        \n",
    "        response_list = [\n",
    "            \"Delhi is the capital of India\",\n",
    "            \"IPL is a poppular league in India\",\n",
    "            \"AI stands for Artificial Intelligence\"\n",
    "        ]\n",
    "        return {'response': random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "679fc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPromptTemplate(Runnable):\n",
    "\n",
    "    def __init__(self, template, input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "    def format(self, input_dict):\n",
    "        return self.template.format(**input_dict)\n",
    "\n",
    "    def invoke(self, input_dict):\n",
    "        return self.template.format(**input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f988f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyStrOutputParser(Runnable):\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Output parser initialized\")\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        return input_data[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b7b58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnableConnector(Runnable):\n",
    "    def __init__(self, runnable_list):\n",
    "        self.runnable_list = runnable_list\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "\n",
    "        local_input_data = input_data\n",
    "\n",
    "        for runnable in self.runnable_list:\n",
    "            local_input_data = runnable.invoke(local_input_data)\n",
    "        \n",
    "        return local_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0650efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized\n"
     ]
    }
   ],
   "source": [
    "# first create a prompt with template and input variables\n",
    "\n",
    "template_prompt = DummyPromptTemplate(\n",
    "    template=\"Write a {length} poem about {topic}\",\n",
    "    input_variables=[\"length\", \"topic\"]\n",
    ")\n",
    "\n",
    "llm = DummyLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d00b9aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output parser initialized\n"
     ]
    }
   ],
   "source": [
    "parser = DummyStrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d1999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableConnector([template_prompt, llm, parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ab0bde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stands for Artificial Intelligence\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({'length': 'long', 'topic': 'Computer'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b01e62",
   "metadata": {},
   "source": [
    "##### Till now we created multiple components and created a chain out of it and generated an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908644e1",
   "metadata": {},
   "source": [
    "#### Now let us Create multiple chains and connect them and see the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a93505a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_prompt_1 = DummyPromptTemplate(\n",
    "    template=\"Write a joke about {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d48e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_prompt_2 = DummyPromptTemplate(\n",
    "    template=\"Explain the following joke: {response}\",\n",
    "    input_variables=[\"response\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708d3012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized\n"
     ]
    }
   ],
   "source": [
    "llm = DummyLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "662e456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output parser initialized\n"
     ]
    }
   ],
   "source": [
    "parser = DummyStrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71f75550",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1 = RunnableConnector([template_prompt_1, llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d2afb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_2 = RunnableConnector([template_prompt_2, llm, parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dca8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableConnector([chain_1, chain_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "553f0146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI stands for Artificial Intelligence'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({'topic': 'AI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff68b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
